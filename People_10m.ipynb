{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adbcdbf9-ca8b-4a7b-9d1d-bff252369930",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, TimestampType\n",
    "\n",
    "schema = StructType([\n",
    "  StructField(\"id\", IntegerType(), True),\n",
    "  StructField(\"firstName\", StringType(), True),\n",
    "  StructField(\"middleName\", StringType(), True),\n",
    "  StructField(\"lastName\", StringType(), True),\n",
    "  StructField(\"gender\", StringType(), True),\n",
    "  StructField(\"birthDate\", TimestampType(), True),\n",
    "  StructField(\"ssn\", StringType(), True),\n",
    "  StructField(\"salary\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "df = spark.read.format(\"csv\").option(\"header\", True).schema(schema).load(\"/Volumes/workspace/people_extract/people_10m/export.csv\")\n",
    "\n",
    "# Create the table if it does not exist. Otherwise, replace the existing table.\n",
    "df.writeTo(\"main.default.people_10m\").createOrReplace()\n",
    "\n",
    "# If you know the table does not already exist, you can call this instead:\n",
    "# df.write.saveAsTable(\"main.default.people_10m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0302cba1-b12e-44c6-8fd0-c01d5128c3a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "(\n",
    "    DeltaTable.createIfNotExists(spark)\n",
    "    .tableName(\"main.default.people_10m\")\n",
    "    .addColumn(\"id\", \"INT\")\n",
    "    .addColumn(\"firstName\", \"STRING\")\n",
    "    .addColumn(\"middleName\", \"STRING\")\n",
    "    .addColumn(\"lastName\", \"STRING\", comment = \"surname\")\n",
    "    .addColumn(\"gender\", \"STRING\")\n",
    "    .addColumn(\"birthDate\", \"TIMESTAMP\")\n",
    "    .addColumn(\"ssn\", \"STRING\")\n",
    "    .addColumn(\"salary\", \"INT\")\n",
    "    .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95e26dc0-863d-4c1b-ad04-4adb811a0d29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
    "from datetime import date\n",
    "\n",
    "schema = StructType([\n",
    "  StructField(\"id\", IntegerType(), True),\n",
    "  StructField(\"firstName\", StringType(), True),\n",
    "  StructField(\"middleName\", StringType(), True),\n",
    "  StructField(\"lastName\", StringType(), True),\n",
    "  StructField(\"gender\", StringType(), True),\n",
    "  StructField(\"birthDate\", DateType(), True),\n",
    "  StructField(\"ssn\", StringType(), True),\n",
    "  StructField(\"salary\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "data = [\n",
    "  (9999998, 'Billy', 'Tommie', 'Luppitt', 'M', date.fromisoformat('1992-09-17'), '953-38-9452', 55250),\n",
    "  (9999999, 'Elias', 'Cyril', 'Leadbetter', 'M', date.fromisoformat('1984-05-22'), '906-51-2137', 48500),\n",
    "  (10000000, 'Joshua', 'Chas', 'Broggio', 'M', date.fromisoformat('1968-07-22'), '988-61-6247', 90000),\n",
    "  (20000001, 'John', '', 'Doe', 'M', date.fromisoformat('1978-01-14'), '345-67-8901', 55500),\n",
    "  (20000002, 'Mary', '', 'Smith', 'F', date.fromisoformat('1982-10-29'), '456-78-9012', 98250),\n",
    "  (20000003, 'Jane', '', 'Doe', 'F', date.fromisoformat('1981-06-25'), '567-89-0123', 89900)\n",
    "]\n",
    "\n",
    "people_10m_updates = spark.createDataFrame(data, schema)\n",
    "people_10m_updates.createTempView(\"people_10m_updates\")\n",
    "\n",
    "# ...\n",
    "\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "deltaTable = DeltaTable.forName(spark, 'main.default.people_10m')\n",
    "\n",
    "(deltaTable.alias(\"people_10m\")\n",
    "  .merge(\n",
    "    people_10m_updates.alias(\"people_10m_updates\"),\n",
    "    \"people_10m.id = people_10m_updates.id\")\n",
    "  .whenMatchedUpdateAll()\n",
    "  .whenNotMatchedInsertAll()\n",
    "  .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cf3aabf-6541-421b-a2d9-3341c7b473dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Querying the above table after merging with the temporary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66023821-2dda-4edb-95a3-7ac9d3d8e84d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.table(\"main.default.people_10m\")\n",
    "df_filtered = df.filter(df[\"id\"] >= 9999998)\n",
    "display(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12959dbc-1fde-4a72-a819-c3706d531838",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Read a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "05929310-e7d3-4095-84c0-7877bf50058e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "people_df = spark.read.table(\"main.default.people_10m\")\n",
    "display(people_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "211cf711-2010-46ad-9c4e-335f31ba99c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Write to a table and Replace data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fbdff38-36a2-4b76-80cf-8c1e59ed24b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.mode(\"append\").saveAsTable(\"main.default.people_10m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4d4bda6-4429-43fc-8fe7-de137dba1220",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").saveAsTable(\"main.default.people_10m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dc096e2-9857-497e-8c84-f7f0afd90157",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Update a table\n",
    "Change the abbrevation of gender from'M or 'F' to 'Male' or 'Female'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "935d02c8-050d-4739-ace0-21da999b98bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "deltaTable = DeltaTable.forName(spark, \"main.default.people_10m\")\n",
    "\n",
    "# Declare the predicate by using a SQL-formatted string.\n",
    "deltaTable.update(\n",
    "  condition = \"gender = 'F'\",\n",
    "  set = { \"gender\": \"'Female'\" }\n",
    ")\n",
    "\n",
    "# Declare the predicate by using Spark SQL functions.\n",
    "deltaTable.update(\n",
    "  condition = col('gender') == 'M',\n",
    "  set = { 'gender': lit('Male') }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9dfd7fa7-08ef-4002-99d1-24bea4d62e1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Delete from a table\n",
    "delete all the values corresponding to the birthdate less than 1955\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f3681d26-cf88-473a-b3ce-8aee023daa5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "deltaTable = DeltaTable.forName(spark, \"main.default.people_10m\")\n",
    "\n",
    "# Declare the predicate by using a SQL-formatted string.\n",
    "deltaTable.delete(\"birthDate < '1955-01-01'\")\n",
    "\n",
    "# Declare the predicate by using Spark SQL functions.\n",
    "deltaTable.delete(col('birthDate') < '1960-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdfe2508-fa22-45c0-8b5e-8a613dcbcc27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Display History of a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "910fafe8-64f8-4cfe-9a1a-7ac81efb033b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "\n",
    "deltaTable = DeltaTable.forName(spark, \"main.default.people_10m\")\n",
    "display(deltaTable.history())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adb93644-0127-45cf-bf03-c3ac0cbab115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Query an earlier version of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5985810-9707-4b67-9e95-b07f7f6ab954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "\n",
    "deltaTable = DeltaTable.forName(spark, \"main.default.people_10m\")\n",
    "deltaHistory = deltaTable.history()\n",
    "\n",
    "display(deltaHistory.where(\"version == 0\"))\n",
    "# Or:\n",
    "display(deltaHistory.where(\"timestamp == '2024-05-15T22:43:15.000+00:00'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfcafbe2-1552-4bf1-b0aa-ba58bd59ca71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "need to use the current time to read the changes made earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9717e79c-17cf-4b07-a138-0273b4c6d451",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.option('versionAsOf', 0).table(\"main.default.people_10m\")\n",
    "# Or:\n",
    "df = spark.read.option('timestampAsOf', '2026-01-12 17:16:28.000+00:00').table(\"main.default.people_10m\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4d6a68a-7dcc-474a-842d-4a6b9f3905fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Optimize a file\n",
    "\n",
    "-might have small files that are after made after making the changes\n",
    "\n",
    "will optimize to a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dc27ba9-0669-4a73-89a3-213b18d120e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "\n",
    "deltaTable = DeltaTable.forName(spark, \"main.default.people_10m\")\n",
    "deltaTable.optimize().executeCompaction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7af5c66e-dcf4-42ee-a32b-e91c5390c986",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eadd5100-1133-4a03-9f26-7a66a9d59441",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Z-order the columns\n",
    "To improve read performance further, you can collocate related information in the same set of files by z-ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ad64994-5e17-4049-ac0e-204a1700c11b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "\n",
    "deltaTable = DeltaTable.forName(spark, \"main.default.people_10m\")\n",
    "deltaTable.optimize().executeZOrderBy(\"gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99a23eb2-d453-4709-b259-c19b48261ac4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Cleanup snapshots with Vacuum\n",
    "-Delta Lake provides snapshot isolation for reads, which means that it is safe to run an optimize operation even while other users or jobs are querying the table. Eventually however, you should clean up old snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ebfa7ef-d519-4958-b0d2-50d4907f5d23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "\n",
    "deltaTable = DeltaTable.forName(spark, \"main.default.people_10m\")\n",
    "deltaTable.vacuum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "449da3ab-43eb-4747-9d55-80ee8f90c03f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Can remove unused data files with Vacuum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "593f99df-8fe5-4a40-96dc-4b94a6323397",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "250a6a0a-fc2d-40a9-84ab-311372be60df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "People_10m",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
